{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network 2.0\n",
    "\n",
    "### Features\n",
    "\n",
    "* New Learning Laws\n",
    "* Previous weights are saved in oprder to keep training the neural network\n",
    "* I use EMG signals to predig the angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way of developing the learning law\n",
    "\n",
    "If we develop the learning laws for a recurrent neural network, we turn out to the following struture\n",
    "\n",
    "__Note in here, the identification error is $\\Delta(k) = x(k)-\\hat{x}(k)$__\n",
    "\n",
    "\\begin{array}{c}\n",
    "tr\\left\\{ \\check{W}_{i}^{\\intercal}(k)\\left(g_{i}\\left[W_{i}\\left(k+1\\right)-W_{i}\\left(k\\right)\\right]+P_{i,1}\\check{W}_{i}(k)\\varPsi_{i}\\varPsi_{i}^{\\top}-PA\\Delta(k)\\varPsi_{i}^{\\top}\\right)\\right\\} =0;\\quad i=\\{1,2\\}\\\\\n",
    "\\varPsi_{1}=\\sigma(\\hat{x}(k));\\quad\\varPsi_{2}=\\varphi(\\hat{x}(k))u(k)\n",
    "\\end{array}\n",
    "\n",
    "Then, we can use the following equivalence for making those trace as zero\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "tr\\left\\{ \\left[\\begin{array}{cc}\n",
    "\\check{W}_{i}^{\\intercal} & 0\\\\\n",
    "0 & \\check{W}_{i}^{\\intercal}\n",
    "\\end{array}\\right]\\Theta\\right\\} =0;\\\\\n",
    "\\Theta=\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]+\\left[\\begin{array}{c}\n",
    "-\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]W_{i}\\left(k\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]-\\left[\\begin{array}{cc}\n",
    "G & -\\sqrt{g_{i}}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}+\\partial G\\\\\n",
    "\\sqrt{g_{i}}PW_{i}(k)+\\partial G & G\n",
    "\\end{array}\\right]\\\\\n",
    "G={\\displaystyle \\frac{PA\\Delta(k)\\varPsi_{i}^{\\top}}{2};}\n",
    "\\end{array}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping terms\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\Theta=\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]+R=0;\\\\\n",
    "R=\\left[\\begin{array}{c}\n",
    "-\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]W_{i}\\left(k\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]-\\left[\\begin{array}{cc}\n",
    "G & -\\sqrt{g_{i}}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}+\\partial G\\\\\n",
    "\\sqrt{g_{i}}PW_{i}(k)+\\partial G & G\n",
    "\\end{array}\\right];\\\\\n",
    "R=\\left[\\begin{array}{cc}\n",
    "-g_{i}W_{i}(k) & -\\sqrt{g_{i}}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\\\\n",
    "\\sqrt{g_{i}}PW_{i}(k) & P_{i,1}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]+\\left[\\begin{array}{cc}\n",
    "-G & \\sqrt{g_{i}}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}-\\partial G\\\\\n",
    "-\\sqrt{g_{i}}PW_{i}(k)-\\partial G & -G\n",
    "\\end{array}\\right];\\\\\n",
    "R=\\left[\\begin{array}{cc}\n",
    "-g_{i}W_{i}(k)-G & -\\partial G\\\\\n",
    "-\\partial G & P_{i,1}W_{i}(k){\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}-G\n",
    "\\end{array}\\right]\n",
    "\\end{array}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now follow the next steps to obtain the learning laws for the weights. First we multiply by a term to cancel the right hand elements of $W_{i}(k+1)$\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\left(\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]=-\\left(\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]R\\\\\n",
    "W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]=-\\left(\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "P_{i,1}\n",
    "\\end{array}\\right]\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]R\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above euation can be rearrange as\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]=-\\left(g_{i}I+P_{i,1}^{2}\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]R\\end{array}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure is for the elements in the right hand of $W_{i}(k+1)$\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "W_{i}\\left(k+1\\right)\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]\\left(\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & {\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]\\right)^{-1}=-\\left(g_{i}I+P_{i}^{2}\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]R\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]\\left(g_{i}I+\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}\\right)^{-1}\\\\\n",
    "W_{i}\\left(k+1\\right)=-\\left(g_{i}I+P_{i}^{2}\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]R\\left[\\begin{array}{c}\n",
    "\\sqrt{g_{i}}I\\\\\n",
    "{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]\\left(g_{i}I+\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}\\right)^{-1}\n",
    "\\end{array}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a furthr development of the elemnts, we can obtain \n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "W_{i}\\left(k+1\\right)=-\\left(g_{i}I+P_{i,1}^{2}\\right)^{-1}\\left[\\begin{array}{cc}\n",
    "\\sqrt{g_{i}}I & P_{i,1}\\end{array}\\right]\\left(\\left[\\begin{array}{c}\n",
    "-g_{i}^{3/2}W_{i}(k)-\\sqrt{g_{i}}G-\\partial G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\\\\n",
    "-\\sqrt{g_{i}}\\partial G+P_{i,1}W_{i}(k)\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}-G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\n",
    "\\end{array}\\right]\\right)\\left(g_{i}I+\\left(\\varPsi_{i}\\varPsi_{i}^{\\top}\\right)^{2}\\right)^{-1};\\\\\n",
    "W_{i}\\left(k+1\\right)=-\\left(g_{i}I+P_{i,1}^{2}\\right)^{-1}\\Big(-g_{i}^{2}W_{i}(k)-g_{i}G-\\sqrt{g_{i}}\\partial G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\\\\n",
    "-\\sqrt{g_{i}}\\partial P_{i,1}G+P_{i,1}^{2}W_{i}(k)\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}-P_{i,1}G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\Big)\\left(g_{i}I+\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}\\right)^{-1}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation function\n",
    "def functionSigma(x,out,c):\n",
    "    s = np.zeros((out,1))\n",
    "    nin = np.shape(x)[0]\n",
    "    \n",
    "    for neuronsOut in range(out):\n",
    "        z = 0\n",
    "        for neuronsIn in range(nin):\n",
    "            z += x[neuronsIn]*c[neuronsIn,neuronsOut]\n",
    "        s[neuronsOut,0] = ((1/(1 + np.exp(z))))\n",
    "    return s\n",
    "\n",
    "def functionPhi(x,out,uSize,c):\n",
    "    s = np.zeros((out,1))#Variable para guardar resultados\n",
    "    nin = np.shape(x)[0]\n",
    "    \n",
    "    for neuronsOut in range(out):\n",
    "        z = 0\n",
    "        for neuronsIn in range(nin):\n",
    "            z += x[neuronsIn]*c[neuronsIn,neuronsOut]\n",
    "        s[neuronsOut,0] = ((1/(1 + np.exp(z))))*(1)\n",
    "    s = s@np.ones((1,uSize))#Multiplicación por una matriz\n",
    "    return s\n",
    "\n",
    "def DSigma(x,out,c):\n",
    "    nin = np.shape(x)[0]\n",
    "    s = np.zeros((out,nin))\n",
    "    Sigma = functionSigma(x,out,c)\n",
    "    for neuronsIn in range(nin):\n",
    "        for neuronsOut in range(out):\n",
    "            Sigma_i = Sigma[neuronsOut,0]\n",
    "            C_i = c[neuronsIn,neuronsOut]\n",
    "            s[neuronsOut,neuronsIn]=(Sigma_i*(1-Sigma_i)*C_i)\n",
    "    return s\n",
    "\n",
    "def DPhi(x,out,u,c):\n",
    "    nin = np.shape(x)[0]\n",
    "    s = np.zeros((out,nin))\n",
    "    uSize = np.shape(u)[0]\n",
    "    Phi = functionPhi(x,out,uSize,c)\n",
    "    for u_i in range(uSize):\n",
    "        for neuronsIn in range(nin):\n",
    "            for neuronsOut in range(out):\n",
    "                Phi_i = Phi[neuronsOut,u_i]\n",
    "                C_i = c[neuronsIn,neuronsOut]\n",
    "                s[neuronsOut,neuronsIn] += (Phi_i*(1-Phi_i)*C_i)*u[u_i,0]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Laws\n",
    "\n",
    "### Output, hidden and input learning laws\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "W_{i}\\left(k+1\\right)=-\\left(g_{i}I+P_{i,1}^{2}\\right)^{-1}\\Big(-g_{i}^{2}W_{i}(k)-g_{i}G-\\sqrt{g_{i}}\\partial G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\\\\n",
    "-\\sqrt{g_{i}}\\partial P_{i,1}G+P_{i,1}^{2}W_{i}(k)\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}-P_{i,1}G{\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\Big)\\left(g_{i}I+\\left({\\displaystyle \\frac{\\varPsi_{i}\\varPsi_{i}^{\\top}}{2}}\\right)^{2}\\right)^{-1},\n",
    "\\\\\\\\\n",
    "\\mathbf{W}_{i,2}(k+1)=\\mathbf{W}_{i,2}(k)\\left(g_{i,2}I-2\\Gamma_{i}^{\\top}(k)P_{i,2}\\Gamma_{i}(k)\\right)\\left(2\\Gamma_{i}^{\\top}(k)P_{i,2}\\Gamma_{i}(k)+g_{i,2}I\\right)^{-1}\\\\\n",
    "+\\Delta^{T}(k)A^{T}P\\Gamma_{i}(k)\\left(2\\Gamma_{i}^{\\top}(k)P_{i,2}\\Gamma_{i}(k)+g_{i,2}I\\right)^{-1}, \n",
    "\\\\\\\\\n",
    "\\mathbf{W}_{i,3}(k+1)=\\mathbf{W}_{i,3}(k)\\left(g_{i,3}I-8\\Upsilon_{i}^{\\top}(k)P_{i,3}\\Upsilon_{i}^{\\top}(k)\\right)\\left(8\\Upsilon_{i}^{\\top}(k)P_{i,3}\\Upsilon_{i}^{\\top}(k)+g_{i,3}I\\right)^{-1} \\\\\n",
    "+\\Delta^{T}(k)A^{T}P\\Upsilon_{i}(k)\\left(8\\Upsilon_{i}^{\\top}(k)P_{i,3}\\Upsilon_{i}^{\\top}(k)+g_{i,3}I\\right)^{-1},\n",
    "\\end{array}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My previous learning laws were to dependent on other functions. In this version,there are independent\n",
    "# Final attempt for the MLRNN\n",
    "# Single Layer RNN\n",
    "def LAW1(W_a,delta,g,P,A,Psi,partial=10):\n",
    "    nRow, nCol = W_a.shape\n",
    "    G = (P@A@delta@Psi.T)/2\n",
    "    P = 7*P\n",
    "    Psi=Psi/(2**(1/2))\n",
    "    gLeft = np.identity(nRow)*g\n",
    "    gRight = np.identity(nCol)*g\n",
    "    leftT = np.linalg.inv(gLeft + P@P)\n",
    "    rightT = np.linalg.inv(gRight + (Psi@Psi.T)@(Psi@Psi.T))\n",
    "    t1 = -g*g*W_a\n",
    "    t2 = -g*G\n",
    "    t3 = -g**(1/2)*partial*G@(Psi@Psi.T)\n",
    "    t4 = -g**(1/2)*partial*P@G\n",
    "    t5 = P@P@W_a@(Psi@Psi.T)@(Psi@Psi.T)\n",
    "    t6 = -P@G@(Psi@Psi.T)\n",
    "    W = -leftT@(t1+t2+t3+t4+t5+t6)@rightT\n",
    "    return W\n",
    "#Second Layer or internal Layer\n",
    "def LAW2(W21_a,W1s,delta,k,P,xh,A,n,Derivative):\n",
    "    W21_aF = np.reshape(np.matrix.flatten(W21_a),(-1,1))#Vectorize the weights vector and also reshape the vector\n",
    "    X_M = np.kron(np.identity(n),xh.T) #Create Kronecker product\n",
    "    Gamma=W1s@Derivative@X_M #Compute Gamma\n",
    "    stateSize = np.shape(xh)[0] #Size of the wieghts\n",
    "    I_K = np.identity(np.shape(W21_a)[0]*np.shape(W21_a)[1])*k #Create identity matrix\n",
    "    Inverse = np.linalg.inv(I_K + 14*Gamma.T@P@Gamma/1) # Compute inverse of matrix\n",
    "    W1 = (W21_aF.T@(I_K - 14*Gamma.T@P@Gamma/1)@Inverse + 1*delta.T@A.T@P@Gamma@Inverse) #Update W\n",
    "    return np.reshape(W1,(-1,stateSize))\n",
    "#Learning Laws Hidden Layer\n",
    "def LAW3(W21_a,W1s,W21s,delta,k,P,xh,A,n,Derivative1,Derivative2):\n",
    "    W21_aF = np.reshape(np.matrix.flatten(W21_a),(-1,1))#Vectorize the weights vector and also reshape the vector\n",
    "    X_M = np.kron(np.identity(n),xh.T) #Create Kronecker product\n",
    "    Gamma=W1s@Derivative1@W21s@Derivative2@X_M #Compute Gamma\n",
    "    stateSize = np.shape(xh)[0] #Size of the wieghts\n",
    "    I_K = np.identity(np.shape(W21_a)[0]*np.shape(W21_a)[1])*k #Create identity matrix\n",
    "    Inverse = np.linalg.inv(I_K + 56*Gamma.T@P@Gamma/1) # Compute inverse of matrix\n",
    "    W1 = (W21_aF.T@(I_K - 56*Gamma.T@P@Gamma/1)@Inverse + 1*delta.T@A.T@P@Gamma@Inverse) #Update W\n",
    "    return np.reshape(W1,(-1,stateSize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
